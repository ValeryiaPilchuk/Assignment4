{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d0517890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports section\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bf8940",
   "metadata": {},
   "source": [
    "## Part 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "43a71b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                 5.1               3.5                1.4               0.2\n",
      "1                 4.9               3.0                1.4               0.2\n",
      "2                 4.7               3.2                1.3               0.2\n",
      "3                 4.6               3.1                1.5               0.2\n",
      "4                 5.0               3.6                1.4               0.2\n",
      "5                 5.4               3.9                1.7               0.4\n",
      "6                 4.6               3.4                1.4               0.3\n",
      "7                 5.0               3.4                1.5               0.2\n",
      "8                 4.4               2.9                1.4               0.2\n",
      "9                 4.9               3.1                1.5               0.1\n",
      "10                5.4               3.7                1.5               0.2\n",
      "11                4.8               3.4                1.6               0.2\n",
      "12                4.8               3.0                1.4               0.1\n",
      "13                4.3               3.0                1.1               0.1\n",
      "14                5.8               4.0                1.2               0.2\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         150.000000        150.000000         150.000000   \n",
      "mean            5.843333          3.057333           3.758000   \n",
      "std             0.828066          0.435866           1.765298   \n",
      "min             4.300000          2.000000           1.000000   \n",
      "25%             5.100000          2.800000           1.600000   \n",
      "50%             5.800000          3.000000           4.350000   \n",
      "75%             6.400000          3.300000           5.100000   \n",
      "max             7.900000          4.400000           6.900000   \n",
      "\n",
      "       petal width (cm)  \n",
      "count        150.000000  \n",
      "mean           1.199333  \n",
      "std            0.762238  \n",
      "min            0.100000  \n",
      "25%            0.300000  \n",
      "50%            1.300000  \n",
      "75%            1.800000  \n",
      "max            2.500000  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset (load remotely, not locally)\n",
    "iris = load_iris() # Load in iris\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names) # create an iris dataframe\n",
    "# Output the first 15 rows of the data\n",
    "print(data.head(15))\n",
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ba8412",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "#### Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aafd1b",
   "metadata": {},
   "source": [
    "The data provided consists of information regarding both the sepal length and width as well as the petal length and width. All of these are considered features. The information provided will be used to classify flowers with different features into an appropriate label of the flower type, Iris Setosa, Iris Versicolor, and Iris Virginica. You can access the labels by viewing iris['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f1249",
   "metadata": {},
   "source": [
    "## Part 2: Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3fec5ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "X = iris['data'] #iris features (X)\n",
    "y = iris['target'] #iris label (y)\n",
    "\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509771cb",
   "metadata": {},
   "source": [
    "## Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3d6d90ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for X_test[1]:\n",
      " [[0.01151064 0.88108184 0.10740752]]\n",
      "Score X & y: \n",
      " 0.98\n",
      "Score: X_test & y_test: \n",
      " 1.0\n",
      "The cross validation scores for X & y: \n",
      " [1.         0.93333333 1.         1.         0.93333333 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "Coefficients: \n",
      " [[-0.4403194   0.88516663 -2.45760445 -0.99311586]\n",
      " [ 0.56942753 -0.2546846  -0.22313114 -0.90139707]\n",
      " [-0.12910813 -0.63048203  2.68073558  1.89451293]]\n",
      "Intercept: \n",
      " [  9.93510942   1.7412485  -11.67635792]\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a LogisticRegression model on the training set\n",
    "logisticRegr = LogisticRegression(max_iter=100000) #Create a LogisticRegression model\n",
    "logisticRegr.fit(X_train, y_train) #Train the model using the training sets\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "prediction = logisticRegr.predict_proba(X_test[1].reshape(1,-1)) #probabilities for X_test[1]\n",
    "print(\"Prediction for X_test[1]:\\n\", prediction) \n",
    "\n",
    "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
    "print(\"Score X & y: \\n\", logisticRegr.score(X, y)) \n",
    "print(\"Score: X_test & y_test: \\n\", logisticRegr.score(X_test, y_test))\n",
    "print(\"The cross validation scores for X & y: \\n\", cross_val_score(logisticRegr, X, y, cv=10))\n",
    "\n",
    "# iv. Extract the coefficents and intercepts for the boundary line(s)\n",
    "print(\"Coefficients: \\n\", logisticRegr.coef_)\n",
    "print(\"Intercept: \\n\", logisticRegr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d20f8",
   "metadata": {},
   "source": [
    "The score reports on the accuracy of the model, the score that we get in regards to the whole model is 0.98. This means that our model predicts the data with 98% accuracy. The score that we get in regards to the the test data of the model model is 1. This means that our model predicts the data with 100% accuracy. When computing the score using cross validation, we get a minimum score of .93 and a maximum of 1 meaning the accuracy ranges between these two values, according to our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2677ece",
   "metadata": {},
   "source": [
    "## Part 4: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "97e06087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sample datapoint X_test[1] \n",
      " [[0.00981581 0.92999486 0.06018933]]\n",
      "Score X & y: \n",
      " 0.9866666666666667\n",
      "Score: X_test & y_test: \n",
      " 1.0\n",
      "The cross validation scores for X & y: \n",
      " [1.         0.93333333 1.         1.         0.86666667 1.\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "Prediction for test dataset: \n",
      " [2 1 2 2 1 0 0 0 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "clf = svm.SVC(kernel='linear', probability=True) #Create a svm Classifier\n",
    "clf.fit(X_train, y_train) #Train the model using the training sets\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "prediction2 = clf.predict_proba(X_test[1].reshape(1,-1))  #probabilities for X_test[1]\n",
    "print(\"Prediction for sample datapoint X_test[1] \\n\", prediction2)\n",
    "\n",
    "# iii. Report on the score for the SVM, what does the score measure?\n",
    "print(\"Score X & y: \\n\", clf.score(X, y)) \n",
    "print(\"Score: X_test & y_test: \\n\", clf.score(X_test, y_test))\n",
    "print(\"The cross validation scores for X & y: \\n\", cross_val_score(clf, X, y, cv=10))\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Prediction for test dataset: \\n\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1168e036",
   "metadata": {},
   "source": [
    "The score reports on the accuracy of the model, the score that we get in regards to the whole model is 0.9867. This means that our model predicts the data with 98.7% accuracy. The score that we get in regards to the the test data of the model model is 1. This means that our model predicts the data with 100% accuracy. When computing the score using cross validation, we get a minimum score of .87 and a maximum of 1 meaning the accuracy ranges between these two values, according to our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f6bf8",
   "metadata": {},
   "source": [
    "## Part 5: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9123598d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00244197 0.90953964 0.08801839]]\n",
      "Score X & y: \n",
      " 0.98\n",
      "Score: X_test & y_test: \n",
      " 1.0\n",
      "The cross validation scores for X & y: \n",
      " [1.         1.         1.         1.         0.86666667 1.\n",
      " 0.86666667 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "mlp = MLPClassifier(random_state=3, max_iter=1000) #Create a Neural Network (MLP Classifier)\n",
    "mlp.fit(X_train, y_train) #Train the model using the training sets\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "prediction3 = mlp.predict_proba(X_test[1].reshape(1,-1))  #probabilities for X_test[1]\n",
    "print(prediction3)\n",
    "\n",
    "# iii. Report on the score for the Neural Network, what does the score measure?\n",
    "print(\"Score X & y: \\n\", mlp.score(X, y)) \n",
    "print(\"Score: X_test & y_test: \\n\", mlp.score(X_test, y_test))\n",
    "print(\"The cross validation scores for X & y: \\n\", cross_val_score(mlp, X, y, cv=10))\n",
    "\n",
    "# iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39756ee",
   "metadata": {},
   "source": [
    "The score reports on the accuracy of the model, the score that we get in regards to the whole model is 0.98. This means that our model predicts the data with 98% accuracy. The score that we get in regards to the the test data of the model model is 1. This means that our model predicts the data with 100% accuracy. When computing the score using cross validation, we get a minimum score of .87 and a maximum of 1 meaning the accuracy ranges between these two values, according to our data.\n",
    "\n",
    "\n",
    "Experimenting with different options for the neural network I could only see the differences in the prediction probabilities with no other change to any of the scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dfb5d6",
   "metadata": {},
   "source": [
    "## Part 6: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d26bd2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00199332 0.92459672 0.07340996]]\n",
      "Score X & y: \n",
      " 0.96\n",
      "Score: X_test & y_test: \n",
      " 1.0\n",
      "The cross validation scores for X & y: \n",
      " [1.         0.93333333 1.         0.93333333 0.86666667 1.\n",
      " 0.93333333 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3) #Create a Neural Network (MLP Classifier)\n",
    "knn.fit(X_train, y_train) #Load the test data into the model\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "prediction4 = mlp.predict_proba(X_test[1].reshape(1,-1)) #probabilities for X_test[1]\n",
    "print(prediction4)\n",
    "\n",
    "# iii. Report on the score for kNN, what does the score measure?\n",
    "print(\"Score X & y: \\n\", knn.score(X, y)) \n",
    "print(\"Score: X_test & y_test: \\n\", knn.score(X_test, y_test))\n",
    "print(\"The cross validation scores for X & y: \\n\", cross_val_score(knn, X, y, cv=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456d906b",
   "metadata": {},
   "source": [
    "The score reports on the accuracy of the model, the score that we get in regards to the whole model is 0.96. This means that our model predicts the data with 96% accuracy. The score that we get in regards to the the test data of the model model is 1. This means that our model predicts the data with 100% accuracy. When computing the score using cross validation, we get a minimum score of .87 and a maximum of 1 meaning the accuracy ranges between these two values, according to our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d5234",
   "metadata": {},
   "source": [
    "## Part 7: Conclusions and takeaways\n",
    "#### In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b2e843",
   "metadata": {},
   "source": [
    "The results of this notebook surprised me and made me doubt myself many times in what I am doing. This is due to the score of many models and classifiers being 1, meaning they predict the dataset with 100% accuracy. This of course has to do with the small amount of test data (15 values), but is still shocking. This means that all of the models we used can accurately predict the species of flower based on petal and sepal dimensions. \n",
    "The model which performed best would be the SVM model. It had the highest prediction score for X and y with 0.9866666666666667. I think that is because the model allows enough of a room for miscalculation between the 3 species of flower which translates to the highest accuracy rate for the 3 species."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
